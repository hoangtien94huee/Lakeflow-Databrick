{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da17bd9",
   "metadata": {},
   "source": [
    "# Bronze to Silver Data Pipeline\n",
    "\n",
    "This notebook ingests raw data from CSV files and creates the bronze table for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d62db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"BronzeToSilver\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a176b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bronze table\n",
    "@dlt.table(\n",
    "    name=\"bronze_table\",\n",
    "    comment=\"Raw sales data ingested from CSV files\"\n",
    ")\n",
    "def bronze_table():\n",
    "    # Define schema for the sales data\n",
    "    schema = StructType([\n",
    "        StructField(\"transaction_id\", StringType(), True),\n",
    "        StructField(\"date\", StringType(), True),\n",
    "        StructField(\"category\", StringType(), True),\n",
    "        StructField(\"product_name\", StringType(), True),\n",
    "        StructField(\"sales_amount\", DoubleType(), True),\n",
    "        StructField(\"quantity\", IntegerType(), True),\n",
    "        StructField(\"customer_id\", StringType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Read CSV data from Unity Catalog Volume\n",
    "    # Path: /Volumes/main/default/demo/sample_sales_data.csv\n",
    "    df = spark.read \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"false\") \\\n",
    "        .schema(schema) \\\n",
    "        .csv(\"/Volumes/main/default/demo/sample_sales_data.csv\")\n",
    "    \n",
    "    # Add metadata columns \n",
    "    df_with_metadata = df.withColumn(\"ingestion_timestamp\", current_timestamp()) \\\n",
    "                        .withColumn(\"source_file\", lit(\"sample_sales_data.csv\"))\n",
    "    \n",
    "    return df_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75b43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for testing (uncomment to generate test data)\n",
    "\"\"\"\n",
    "sample_data = [\n",
    "    (\"TXN001\", \"2024-01-01\", \"Electronics\", \"Laptop\", 1200.00, 1, \"CUST001\"),\n",
    "    (\"TXN002\", \"2024-01-02\", \"Clothing\", \"T-Shirt\", 25.99, 2, \"CUST002\"),\n",
    "    (\"TXN003\", \"2024-01-03\", \"Electronics\", \"Mouse\", 15.50, 1, \"CUST003\"),\n",
    "    (\"TXN004\", \"2024-01-04\", \"Books\", \"Python Guide\", 45.00, 1, \"CUST001\"),\n",
    "    (\"TXN005\", \"2024-01-05\", \"Clothing\", \"Jeans\", 89.99, 1, \"CUST004\"),\n",
    "    (\"TXN006\", \"2024-01-06\", \"Electronics\", \"Keyboard\", 75.00, 1, \"CUST005\"),\n",
    "    (\"TXN007\", \"2024-01-07\", \"Books\", \"Data Science\", 55.00, 2, \"CUST002\"),\n",
    "    (\"TXN008\", \"2024-01-08\", \"Clothing\", \"Jacket\", 199.99, 1, \"CUST003\"),\n",
    "    (\"TXN009\", \"2024-01-09\", \"Electronics\", \"Monitor\", 350.00, 1, \"CUST006\"),\n",
    "    (\"TXN010\", \"2024-01-10\", \"Books\", \"Machine Learning\", 65.00, 1, \"CUST004\")\n",
    "]\n",
    "\n",
    "columns = [\"transaction_id\", \"date\", \"category\", \"product_name\", \"sales_amount\", \"quantity\", \"customer_id\"]\n",
    "sample_df = spark.createDataFrame(sample_data, columns)\n",
    "\n",
    "# Save sample data to Unity Catalog Volume (run this once to create test data)\n",
    "sample_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/main/default/demo/sample_sales_data.csv\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Bronze layer setup complete. Data will be ingested from /Volumes/main/default/demo/sample_sales_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
